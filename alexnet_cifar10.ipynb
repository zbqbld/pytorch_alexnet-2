{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "alexnet_cifar10.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhdbw1022/pytorch_alexnet/blob/master/alexnet_cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz8hvcRNmt74",
        "colab_type": "code",
        "outputId": "38875535-d4e4-4539-8c64-e08c40674549",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install tensorboardX\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "from tensorboardX import SummaryWriter\n",
        "import numpy as np\n",
        "import os\n",
        "import _pickle as cPickle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "     # 定义全局变量\n",
        "modelPath = './model.pkl'\n",
        "batchSize = 5\n",
        "nEpochs = 20\n",
        "numPrint = 1000\n",
        "# 定义Summary_Writer\n",
        "writer = SummaryWriter('./Result')   # 数据存放在这个文件夹\n",
        "# cuda\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(size=(227, 227)),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),  # 将图片转换为Tensor,归一化至[0,1]\n",
        "    normalize\n",
        "])\n",
        "\n",
        "# 加载数据集 (训练集和测试集)\n",
        "trainset = torchvision.datasets.CIFAR10(root='./Cifar-10', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./Cifar-10', train=False, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchSize, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batchSize, shuffle=False)\n",
        "\n",
        "\n",
        "\n",
        "#CURRENT_DIR = os.getcwd()\n",
        "# \n",
        "#\n",
        "#def read_cifar10_train_data(dataset_file_path):\n",
        "#    data_dir = dataset_file_path\n",
        "#    train_name = 'data_batch_'\n",
        "#    train_X = None\n",
        "#    train_Y = None\n",
        "#\n",
        "#    # train data\n",
        "#    for i in range(1,6):\n",
        "#        file_path = data_dir+train_name+str(i)\n",
        "#        with open(file_path, 'rb') as fo:\n",
        "#            \n",
        "#            dict = cPickle.load(fo)\n",
        "#           \n",
        "#            if  train_X is None:\n",
        "#                train_X = dict['data']\n",
        "#                train_Y = dict['labels']\n",
        "#            else:\n",
        "#                train_X = np.concatenate((train_X, dict['data']), axis=0)\n",
        "#                train_Y = np.concatenate((train_Y, dict['labels']), axis=0)\n",
        "#                \n",
        "# \n",
        "#    \n",
        "#    train_X = train_X.reshape((50000, 3, 32, 32)).transpose(0, 2, 3, 1)\n",
        "#\n",
        "#    train_y_vec = np.zeros((len(train_Y), 10), dtype=np.float)\n",
        "#\n",
        "#    for i, label in enumerate(train_Y):\n",
        "#        train_y_vec[i, int(train_Y[i])] = 1.  # y_vec[1,3] means #2 row, #4column\n",
        "#\n",
        "# \n",
        "#    return train_X, train_y_vec\n",
        "#\n",
        "#\n",
        "#def read_cifar10_test_data(dataset_file_path):\n",
        "#    data_dir = dataset_file_path\n",
        "#    test_name = 'test_batch'\n",
        "#    test_X = None\n",
        "#    test_Y = None\n",
        "#      \n",
        "#    # test_data\n",
        "#    file_path = data_dir + test_name\n",
        "#    with open(file_path, 'rb') as fo:\n",
        "#        dict =cPickle.load(fo,encoding='iso-8859-1')\n",
        "# \n",
        "#        test_X = dict['data']\n",
        "#        test_Y = dict['labels']\n",
        "#\n",
        "#    test_X = test_X.reshape((10000, 3, 32, 32)).transpose(0, 2, 3, 1)\n",
        "#\n",
        "#    test_y_vec = np.zeros((len(test_Y), 10), dtype=np.float)\n",
        "#\n",
        "#    for i, label in enumerate(test_Y):\n",
        "#        test_y_vec[i, int(test_Y[i])] = 1.  # y_vec[1,3] means #2 row, #4column\n",
        "# \n",
        "#    return test_X, test_y_vec\n",
        "\n",
        "\n",
        "\n",
        "#class BatchReadData(object):\n",
        "#\n",
        "#    def __init__(self, dataset_file_path, output_size=[227, 227], train_data=True, shuffle=False):\n",
        "#        self.output_size = output_size\n",
        "#        self.shuffle = shuffle\n",
        "#\n",
        "#        self.pointer = 0\n",
        "#        # 读数据\n",
        "#        if train_data:\n",
        "#            self.images, self.labels = read_cifar10_train_data(dataset_file_path)\n",
        "#        else:\n",
        "#            self.images, self.labels = read_cifar10_test_data(dataset_file_path)\n",
        "#        \n",
        "#        # Shuffle the data\n",
        "#        if self.shuffle:\n",
        "#            self.shuffle_data()\n",
        "#            \n",
        "#            \n",
        "#    def reset_pointer(self):\n",
        "#        self.pointer = 0\n",
        "#        \n",
        "#        if self.shuffle:\n",
        "#            self.shuffle_data()\n",
        "#            \n",
        "#    def shuffle_data(self):\n",
        "#        temp_images = self.images[:]\n",
        "#        temp_labels = self.labels[:]\n",
        "#        \n",
        "#        self.images = []\n",
        "#        self.labels = []\n",
        "#\n",
        "#        idx = np.random.permutation(len(temp_labels))\n",
        "#        for i in idx:\n",
        "#            self.images.append(temp_images[i])\n",
        "#            self.labels.append(temp_labels[i])\n",
        "#            \n",
        "#            \n",
        "#    def next_batch(self, batch_size):\n",
        "#        # Get next batch of image (path) and labels\n",
        "#        paths = self.images[self.pointer:(self.pointer+batch_size)]\n",
        "#        labels = self.labels[self.pointer:(self.pointer+batch_size)]        \n",
        "#        \n",
        "#        print (len(paths))\n",
        "#        print (paths[0].shape)\n",
        "#        \n",
        "#        # Update pointer\n",
        "#        self.pointer += batch_size\n",
        "#        \n",
        "#        # Read images\n",
        "#        images = np.ndarray([batch_size, self.output_size[0], self.output_size[1], 3])\n",
        "#        #images = np.zeros((batch_size, self.output_size[0], self.output_size[1], 3))\n",
        "#        \n",
        "#        for i in range(len(paths)):\n",
        "#            \n",
        "#            img = paths[i]           \n",
        "#\n",
        "#            # Resize the image for output\n",
        "#            img = Image.fromarray(img)\n",
        "#            img = np.array(img.resize((227,227),Image.BICUBIC))# 修改分辨率，再转为array类\n",
        "#            #img = cv2.resize(img, (self.output_size[0], self.output_size[0]))     #  这上面的两种方法都可以\n",
        "#            images[i,:,:,:] = img\n",
        "#\n",
        "#        return images/255., labels\n",
        "#    # 测试代码 \n",
        "#dataset_file_path = CURRENT_DIR+'/Cifar-10/cifar-10-batches-py/'\n",
        "#\n",
        "#\n",
        "#one = BatchReadData(dataset_file_path, [227, 227],False, False)\n",
        "#\n",
        "#for i in range(10):\n",
        "#     \n",
        "#    images, labels = one.next_batch(100)\n",
        "#     \n",
        "#    fig, axarr = plt.subplots(1, 2) \n",
        "#    axarr[0].imshow(images[0]) \n",
        "#    axarr[1].imshow(images[1])\n",
        "#    print (labels[0], labels[1])\n",
        "#    plt.show()\n",
        "#    if i==3:\n",
        "#        one.reset_pointer()\n",
        "\n",
        "\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self,num_classes=10):\n",
        "        super(AlexNet,self).__init__()\n",
        "        self.feature_extraction = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3,out_channels=96,kernel_size=11,stride=4,padding=2,bias=False),\n",
        "            nn.BatchNorm2d(96),\n",
        "            nn.ReLU(True),\n",
        " \n",
        "            nn.MaxPool2d(kernel_size=3,stride=2,padding=0),\n",
        "            nn.Conv2d(in_channels=96,out_channels=192,kernel_size=5,stride=1,padding=2,bias=False),\n",
        "            nn.BatchNorm2d(192),\n",
        "            nn.ReLU(True),\n",
        " \n",
        "            nn.MaxPool2d(kernel_size=3,stride=2,padding=0),\n",
        "            nn.Conv2d(in_channels=192,out_channels=384,kernel_size=3,stride=1,padding=1,bias=False),\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU(True),\n",
        " \n",
        "            nn.Conv2d(in_channels=384,out_channels=256,kernel_size=3,stride=1,padding=1,bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        " \n",
        "            nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,stride=1,padding=1,bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        " \n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(in_features=256*6*6,out_features=4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(in_features=4096, out_features=4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(in_features=4096, out_features=num_classes),\n",
        "        )\n",
        "    def forward(self,x):\n",
        "        x = self.feature_extraction(x)\n",
        "        x = x.view(x.size(0),256*6*6)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = AlexNet().to(device)\n",
        "\n",
        "# 使用测试数据测试网络\n",
        "def Accuracy():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():  # 训练集中不需要反向传播\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device) # 将输入和目标在每一步都送入GPU\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)  # 返回每一行中最大值的那个元素，且返回其索引\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
        "    return 100.0 * correct / total\n",
        "\n",
        "# 训练函数\n",
        "def train():\n",
        "    # 定义损失函数和优化器\n",
        "    criterion = nn.CrossEntropyLoss()  # 交叉熵损失\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)  # 随机梯度下降\n",
        "    iter = 0\n",
        "    num = 1\n",
        "    # 训练网络\n",
        "    for epoch in range(nEpochs):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            iter = iter + 1\n",
        "            # 取数据\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)  # 将输入和目标在每一步都送入GPU\n",
        "            # 将梯度置零\n",
        "            optimizer.zero_grad()\n",
        "            # 训练\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels).to(device)\n",
        "            loss.backward()   # 反向传播\n",
        "            writer.add_scalar('loss', loss.item(), iter)\n",
        "            optimizer.step()  # 优化\n",
        "            # 统计数据\n",
        "            running_loss += loss.item()\n",
        "            if i % numPrint == 999:    # 每 batchsize * numPrint 张图片，打印一次\n",
        "                print('epoch: %d\\t batch: %d\\t loss: %.6f' % (epoch + 1, i + 1, running_loss / (batchSize*numPrint)))\n",
        "                running_loss = 0.0\n",
        "                writer.add_scalar('accuracy', Accuracy(), num + 1)\n",
        "                num = num + 1\n",
        "    # 保存模型\n",
        "    torch.save(net, './model.pkl')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # 如果模型存在，加载模型\n",
        "    if os.path.exists(modelPath):\n",
        "        print('model exits')\n",
        "        net = torch.load(modelPath)\n",
        "        print('model loaded')\n",
        "    else:\n",
        "        print('model not exits')\n",
        "    print('Training Started')\n",
        "    train()\n",
        "    writer.close()\n",
        "    print('Training Finished')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/5c/e918d9f190baab8d55bad52840d8091dd5114cc99f03eaa6d72d404503cc/tensorboardX-1.9-py2.py3-none-any.whl (190kB)\n",
            "\r\u001b[K     |█▊                              | 10kB 17.6MB/s eta 0:00:01\r\u001b[K     |███▍                            | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 30kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 61kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 71kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 81kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 92kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 102kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 112kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 122kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 133kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 143kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 153kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 163kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 174kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 184kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 194kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.17.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (41.4.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-1.9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./Cifar-10/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:02, 57868858.61it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./Cifar-10/cifar-10-python.tar.gz to ./Cifar-10\n",
            "Files already downloaded and verified\n",
            "model not exits\n",
            "Training Started\n",
            "epoch: 1\t batch: 1000\t loss: 0.409240\n",
            "Accuracy of the network on the 10000 test images: 30 %\n",
            "epoch: 1\t batch: 2000\t loss: 0.362020\n",
            "Accuracy of the network on the 10000 test images: 38 %\n",
            "epoch: 1\t batch: 3000\t loss: 0.334070\n",
            "Accuracy of the network on the 10000 test images: 39 %\n",
            "epoch: 1\t batch: 4000\t loss: 0.328885\n",
            "Accuracy of the network on the 10000 test images: 42 %\n",
            "epoch: 1\t batch: 5000\t loss: 0.313853\n",
            "Accuracy of the network on the 10000 test images: 43 %\n",
            "epoch: 1\t batch: 6000\t loss: 0.303270\n",
            "Accuracy of the network on the 10000 test images: 43 %\n",
            "epoch: 1\t batch: 7000\t loss: 0.301450\n",
            "Accuracy of the network on the 10000 test images: 43 %\n",
            "epoch: 1\t batch: 8000\t loss: 0.292954\n",
            "Accuracy of the network on the 10000 test images: 46 %\n",
            "epoch: 1\t batch: 9000\t loss: 0.281095\n",
            "Accuracy of the network on the 10000 test images: 49 %\n",
            "epoch: 1\t batch: 10000\t loss: 0.272663\n",
            "Accuracy of the network on the 10000 test images: 50 %\n",
            "epoch: 2\t batch: 1000\t loss: 0.264875\n",
            "Accuracy of the network on the 10000 test images: 49 %\n",
            "epoch: 2\t batch: 2000\t loss: 0.259728\n",
            "Accuracy of the network on the 10000 test images: 52 %\n",
            "epoch: 2\t batch: 3000\t loss: 0.255505\n",
            "Accuracy of the network on the 10000 test images: 56 %\n",
            "epoch: 2\t batch: 4000\t loss: 0.248425\n",
            "Accuracy of the network on the 10000 test images: 57 %\n",
            "epoch: 2\t batch: 5000\t loss: 0.240615\n",
            "Accuracy of the network on the 10000 test images: 55 %\n",
            "epoch: 2\t batch: 6000\t loss: 0.235902\n",
            "Accuracy of the network on the 10000 test images: 57 %\n",
            "epoch: 2\t batch: 7000\t loss: 0.236880\n",
            "Accuracy of the network on the 10000 test images: 61 %\n",
            "epoch: 2\t batch: 8000\t loss: 0.232892\n",
            "Accuracy of the network on the 10000 test images: 60 %\n",
            "epoch: 2\t batch: 9000\t loss: 0.231082\n",
            "Accuracy of the network on the 10000 test images: 59 %\n",
            "epoch: 2\t batch: 10000\t loss: 0.228939\n",
            "Accuracy of the network on the 10000 test images: 60 %\n",
            "epoch: 3\t batch: 1000\t loss: 0.218315\n",
            "Accuracy of the network on the 10000 test images: 62 %\n",
            "epoch: 3\t batch: 2000\t loss: 0.210602\n",
            "Accuracy of the network on the 10000 test images: 64 %\n",
            "epoch: 3\t batch: 3000\t loss: 0.211920\n",
            "Accuracy of the network on the 10000 test images: 61 %\n",
            "epoch: 3\t batch: 4000\t loss: 0.215421\n",
            "Accuracy of the network on the 10000 test images: 61 %\n",
            "epoch: 3\t batch: 5000\t loss: 0.211051\n",
            "Accuracy of the network on the 10000 test images: 63 %\n",
            "epoch: 3\t batch: 6000\t loss: 0.212172\n",
            "Accuracy of the network on the 10000 test images: 63 %\n",
            "epoch: 3\t batch: 7000\t loss: 0.202140\n",
            "Accuracy of the network on the 10000 test images: 64 %\n",
            "epoch: 3\t batch: 8000\t loss: 0.203565\n",
            "Accuracy of the network on the 10000 test images: 63 %\n",
            "epoch: 3\t batch: 9000\t loss: 0.203100\n",
            "Accuracy of the network on the 10000 test images: 66 %\n",
            "epoch: 3\t batch: 10000\t loss: 0.197713\n",
            "Accuracy of the network on the 10000 test images: 66 %\n",
            "epoch: 4\t batch: 1000\t loss: 0.188469\n",
            "Accuracy of the network on the 10000 test images: 65 %\n",
            "epoch: 4\t batch: 2000\t loss: 0.196302\n",
            "Accuracy of the network on the 10000 test images: 66 %\n",
            "epoch: 4\t batch: 3000\t loss: 0.188754\n",
            "Accuracy of the network on the 10000 test images: 67 %\n",
            "epoch: 4\t batch: 4000\t loss: 0.193068\n",
            "Accuracy of the network on the 10000 test images: 68 %\n",
            "epoch: 4\t batch: 5000\t loss: 0.192338\n",
            "Accuracy of the network on the 10000 test images: 66 %\n",
            "epoch: 4\t batch: 6000\t loss: 0.185697\n",
            "Accuracy of the network on the 10000 test images: 68 %\n",
            "epoch: 4\t batch: 7000\t loss: 0.183290\n",
            "Accuracy of the network on the 10000 test images: 67 %\n",
            "epoch: 4\t batch: 8000\t loss: 0.177744\n",
            "Accuracy of the network on the 10000 test images: 67 %\n",
            "epoch: 4\t batch: 9000\t loss: 0.186108\n",
            "Accuracy of the network on the 10000 test images: 68 %\n",
            "epoch: 4\t batch: 10000\t loss: 0.177414\n",
            "Accuracy of the network on the 10000 test images: 70 %\n",
            "epoch: 5\t batch: 1000\t loss: 0.172132\n",
            "Accuracy of the network on the 10000 test images: 69 %\n",
            "epoch: 5\t batch: 2000\t loss: 0.171258\n",
            "Accuracy of the network on the 10000 test images: 70 %\n",
            "epoch: 5\t batch: 3000\t loss: 0.171729\n",
            "Accuracy of the network on the 10000 test images: 69 %\n",
            "epoch: 5\t batch: 4000\t loss: 0.171424\n",
            "Accuracy of the network on the 10000 test images: 67 %\n",
            "epoch: 5\t batch: 5000\t loss: 0.170147\n",
            "Accuracy of the network on the 10000 test images: 70 %\n",
            "epoch: 5\t batch: 6000\t loss: 0.171728\n",
            "Accuracy of the network on the 10000 test images: 71 %\n",
            "epoch: 5\t batch: 7000\t loss: 0.169413\n",
            "Accuracy of the network on the 10000 test images: 71 %\n",
            "epoch: 5\t batch: 8000\t loss: 0.164699\n",
            "Accuracy of the network on the 10000 test images: 71 %\n",
            "epoch: 5\t batch: 9000\t loss: 0.165824\n",
            "Accuracy of the network on the 10000 test images: 70 %\n",
            "epoch: 5\t batch: 10000\t loss: 0.161636\n",
            "Accuracy of the network on the 10000 test images: 69 %\n",
            "epoch: 6\t batch: 1000\t loss: 0.160413\n",
            "Accuracy of the network on the 10000 test images: 71 %\n",
            "epoch: 6\t batch: 2000\t loss: 0.159991\n",
            "Accuracy of the network on the 10000 test images: 71 %\n",
            "epoch: 6\t batch: 3000\t loss: 0.159685\n",
            "Accuracy of the network on the 10000 test images: 71 %\n",
            "epoch: 6\t batch: 4000\t loss: 0.157307\n",
            "Accuracy of the network on the 10000 test images: 72 %\n",
            "epoch: 6\t batch: 5000\t loss: 0.154117\n",
            "Accuracy of the network on the 10000 test images: 72 %\n",
            "epoch: 6\t batch: 6000\t loss: 0.152380\n",
            "Accuracy of the network on the 10000 test images: 72 %\n",
            "epoch: 6\t batch: 7000\t loss: 0.154999\n",
            "Accuracy of the network on the 10000 test images: 72 %\n",
            "epoch: 6\t batch: 8000\t loss: 0.154186\n",
            "Accuracy of the network on the 10000 test images: 73 %\n",
            "epoch: 6\t batch: 9000\t loss: 0.157036\n",
            "Accuracy of the network on the 10000 test images: 73 %\n",
            "epoch: 6\t batch: 10000\t loss: 0.153661\n",
            "Accuracy of the network on the 10000 test images: 73 %\n",
            "epoch: 7\t batch: 1000\t loss: 0.149241\n",
            "Accuracy of the network on the 10000 test images: 72 %\n",
            "epoch: 7\t batch: 2000\t loss: 0.144397\n",
            "Accuracy of the network on the 10000 test images: 70 %\n",
            "epoch: 7\t batch: 3000\t loss: 0.145198\n",
            "Accuracy of the network on the 10000 test images: 73 %\n",
            "epoch: 7\t batch: 4000\t loss: 0.144440\n",
            "Accuracy of the network on the 10000 test images: 73 %\n",
            "epoch: 7\t batch: 5000\t loss: 0.148831\n",
            "Accuracy of the network on the 10000 test images: 73 %\n",
            "epoch: 7\t batch: 6000\t loss: 0.145761\n",
            "Accuracy of the network on the 10000 test images: 75 %\n",
            "epoch: 7\t batch: 7000\t loss: 0.148204\n",
            "Accuracy of the network on the 10000 test images: 73 %\n",
            "epoch: 7\t batch: 8000\t loss: 0.143414\n",
            "Accuracy of the network on the 10000 test images: 74 %\n",
            "epoch: 7\t batch: 9000\t loss: 0.142058\n",
            "Accuracy of the network on the 10000 test images: 75 %\n",
            "epoch: 7\t batch: 10000\t loss: 0.139396\n",
            "Accuracy of the network on the 10000 test images: 73 %\n",
            "epoch: 8\t batch: 1000\t loss: 0.137277\n",
            "Accuracy of the network on the 10000 test images: 74 %\n",
            "epoch: 8\t batch: 2000\t loss: 0.134095\n",
            "Accuracy of the network on the 10000 test images: 74 %\n",
            "epoch: 8\t batch: 3000\t loss: 0.135194\n",
            "Accuracy of the network on the 10000 test images: 75 %\n",
            "epoch: 8\t batch: 4000\t loss: 0.139770\n",
            "Accuracy of the network on the 10000 test images: 75 %\n",
            "epoch: 8\t batch: 5000\t loss: 0.135716\n",
            "Accuracy of the network on the 10000 test images: 75 %\n",
            "epoch: 8\t batch: 6000\t loss: 0.136757\n",
            "Accuracy of the network on the 10000 test images: 75 %\n",
            "epoch: 8\t batch: 7000\t loss: 0.137265\n",
            "Accuracy of the network on the 10000 test images: 74 %\n",
            "epoch: 8\t batch: 8000\t loss: 0.131170\n",
            "Accuracy of the network on the 10000 test images: 75 %\n",
            "epoch: 8\t batch: 9000\t loss: 0.131486\n",
            "Accuracy of the network on the 10000 test images: 76 %\n",
            "epoch: 8\t batch: 10000\t loss: 0.131591\n",
            "Accuracy of the network on the 10000 test images: 76 %\n",
            "epoch: 9\t batch: 1000\t loss: 0.127815\n",
            "Accuracy of the network on the 10000 test images: 76 %\n",
            "epoch: 9\t batch: 2000\t loss: 0.125653\n",
            "Accuracy of the network on the 10000 test images: 75 %\n",
            "epoch: 9\t batch: 3000\t loss: 0.130402\n",
            "Accuracy of the network on the 10000 test images: 76 %\n",
            "epoch: 9\t batch: 4000\t loss: 0.125584\n",
            "Accuracy of the network on the 10000 test images: 76 %\n",
            "epoch: 9\t batch: 5000\t loss: 0.128550\n",
            "Accuracy of the network on the 10000 test images: 75 %\n",
            "epoch: 9\t batch: 6000\t loss: 0.129405\n",
            "Accuracy of the network on the 10000 test images: 77 %\n",
            "epoch: 9\t batch: 7000\t loss: 0.125026\n",
            "Accuracy of the network on the 10000 test images: 77 %\n",
            "epoch: 9\t batch: 8000\t loss: 0.128365\n",
            "Accuracy of the network on the 10000 test images: 76 %\n",
            "epoch: 9\t batch: 9000\t loss: 0.122762\n",
            "Accuracy of the network on the 10000 test images: 76 %\n",
            "epoch: 9\t batch: 10000\t loss: 0.122218\n",
            "Accuracy of the network on the 10000 test images: 77 %\n",
            "epoch: 10\t batch: 1000\t loss: 0.117192\n",
            "Accuracy of the network on the 10000 test images: 77 %\n",
            "epoch: 10\t batch: 2000\t loss: 0.118108\n",
            "Accuracy of the network on the 10000 test images: 77 %\n",
            "epoch: 10\t batch: 3000\t loss: 0.118825\n",
            "Accuracy of the network on the 10000 test images: 77 %\n",
            "epoch: 10\t batch: 4000\t loss: 0.123150\n",
            "Accuracy of the network on the 10000 test images: 76 %\n",
            "epoch: 10\t batch: 5000\t loss: 0.118170\n",
            "Accuracy of the network on the 10000 test images: 77 %\n",
            "epoch: 10\t batch: 6000\t loss: 0.122605\n",
            "Accuracy of the network on the 10000 test images: 77 %\n",
            "epoch: 10\t batch: 7000\t loss: 0.114680\n",
            "Accuracy of the network on the 10000 test images: 77 %\n",
            "epoch: 10\t batch: 8000\t loss: 0.116496\n",
            "Accuracy of the network on the 10000 test images: 78 %\n",
            "epoch: 10\t batch: 9000\t loss: 0.119820\n",
            "Accuracy of the network on the 10000 test images: 78 %\n",
            "epoch: 10\t batch: 10000\t loss: 0.117642\n",
            "Accuracy of the network on the 10000 test images: 78 %\n",
            "epoch: 11\t batch: 1000\t loss: 0.110485\n",
            "Accuracy of the network on the 10000 test images: 77 %\n",
            "epoch: 11\t batch: 2000\t loss: 0.109251\n",
            "Accuracy of the network on the 10000 test images: 78 %\n",
            "epoch: 11\t batch: 3000\t loss: 0.110502\n",
            "Accuracy of the network on the 10000 test images: 77 %\n",
            "epoch: 11\t batch: 4000\t loss: 0.114906\n",
            "Accuracy of the network on the 10000 test images: 78 %\n",
            "epoch: 11\t batch: 5000\t loss: 0.110733\n",
            "Accuracy of the network on the 10000 test images: 78 %\n",
            "epoch: 11\t batch: 6000\t loss: 0.114819\n",
            "Accuracy of the network on the 10000 test images: 78 %\n",
            "epoch: 11\t batch: 7000\t loss: 0.110702\n",
            "Accuracy of the network on the 10000 test images: 78 %\n",
            "epoch: 11\t batch: 8000\t loss: 0.113651\n",
            "Accuracy of the network on the 10000 test images: 78 %\n",
            "epoch: 11\t batch: 9000\t loss: 0.109967\n",
            "Accuracy of the network on the 10000 test images: 78 %\n",
            "epoch: 11\t batch: 10000\t loss: 0.109426\n",
            "Accuracy of the network on the 10000 test images: 79 %\n",
            "epoch: 12\t batch: 1000\t loss: 0.103784\n",
            "Accuracy of the network on the 10000 test images: 79 %\n",
            "epoch: 12\t batch: 2000\t loss: 0.109462\n",
            "Accuracy of the network on the 10000 test images: 78 %\n",
            "epoch: 12\t batch: 3000\t loss: 0.109792\n",
            "Accuracy of the network on the 10000 test images: 79 %\n",
            "epoch: 12\t batch: 4000\t loss: 0.106529\n",
            "Accuracy of the network on the 10000 test images: 79 %\n",
            "epoch: 12\t batch: 5000\t loss: 0.107541\n",
            "Accuracy of the network on the 10000 test images: 79 %\n",
            "epoch: 12\t batch: 6000\t loss: 0.111249\n",
            "Accuracy of the network on the 10000 test images: 79 %\n",
            "epoch: 12\t batch: 7000\t loss: 0.103421\n",
            "Accuracy of the network on the 10000 test images: 79 %\n",
            "epoch: 12\t batch: 8000\t loss: 0.109589\n",
            "Accuracy of the network on the 10000 test images: 79 %\n",
            "epoch: 12\t batch: 9000\t loss: 0.104309\n",
            "Accuracy of the network on the 10000 test images: 79 %\n",
            "epoch: 12\t batch: 10000\t loss: 0.102873\n",
            "Accuracy of the network on the 10000 test images: 79 %\n",
            "epoch: 13\t batch: 1000\t loss: 0.098599\n",
            "Accuracy of the network on the 10000 test images: 79 %\n",
            "epoch: 13\t batch: 2000\t loss: 0.099943\n",
            "Accuracy of the network on the 10000 test images: 79 %\n",
            "epoch: 13\t batch: 3000\t loss: 0.106561\n",
            "Accuracy of the network on the 10000 test images: 79 %\n",
            "epoch: 13\t batch: 4000\t loss: 0.097168\n",
            "Accuracy of the network on the 10000 test images: 80 %\n",
            "epoch: 13\t batch: 5000\t loss: 0.099916\n",
            "Accuracy of the network on the 10000 test images: 79 %\n",
            "epoch: 13\t batch: 6000\t loss: 0.102400\n",
            "Accuracy of the network on the 10000 test images: 79 %\n",
            "epoch: 13\t batch: 7000\t loss: 0.100397\n",
            "Accuracy of the network on the 10000 test images: 80 %\n",
            "epoch: 13\t batch: 8000\t loss: 0.100298\n",
            "Accuracy of the network on the 10000 test images: 80 %\n",
            "epoch: 13\t batch: 9000\t loss: 0.099825\n",
            "Accuracy of the network on the 10000 test images: 80 %\n",
            "epoch: 13\t batch: 10000\t loss: 0.096805\n",
            "Accuracy of the network on the 10000 test images: 79 %\n",
            "epoch: 14\t batch: 1000\t loss: 0.090734\n",
            "Accuracy of the network on the 10000 test images: 80 %\n",
            "epoch: 14\t batch: 2000\t loss: 0.101711\n",
            "Accuracy of the network on the 10000 test images: 80 %\n",
            "epoch: 14\t batch: 3000\t loss: 0.090912\n",
            "Accuracy of the network on the 10000 test images: 79 %\n",
            "epoch: 14\t batch: 4000\t loss: 0.097093\n",
            "Accuracy of the network on the 10000 test images: 81 %\n",
            "epoch: 14\t batch: 5000\t loss: 0.091526\n",
            "Accuracy of the network on the 10000 test images: 81 %\n",
            "epoch: 14\t batch: 6000\t loss: 0.095460\n",
            "Accuracy of the network on the 10000 test images: 80 %\n",
            "epoch: 14\t batch: 7000\t loss: 0.097479\n",
            "Accuracy of the network on the 10000 test images: 80 %\n",
            "epoch: 14\t batch: 8000\t loss: 0.096170\n",
            "Accuracy of the network on the 10000 test images: 80 %\n",
            "epoch: 14\t batch: 9000\t loss: 0.095115\n",
            "Accuracy of the network on the 10000 test images: 81 %\n",
            "epoch: 14\t batch: 10000\t loss: 0.094597\n",
            "Accuracy of the network on the 10000 test images: 81 %\n",
            "epoch: 15\t batch: 1000\t loss: 0.089871\n",
            "Accuracy of the network on the 10000 test images: 81 %\n",
            "epoch: 15\t batch: 2000\t loss: 0.089046\n",
            "Accuracy of the network on the 10000 test images: 81 %\n",
            "epoch: 15\t batch: 3000\t loss: 0.090192\n",
            "Accuracy of the network on the 10000 test images: 80 %\n",
            "epoch: 15\t batch: 4000\t loss: 0.084979\n",
            "Accuracy of the network on the 10000 test images: 81 %\n",
            "epoch: 15\t batch: 5000\t loss: 0.093403\n",
            "Accuracy of the network on the 10000 test images: 81 %\n",
            "epoch: 15\t batch: 6000\t loss: 0.087788\n",
            "Accuracy of the network on the 10000 test images: 80 %\n",
            "epoch: 15\t batch: 7000\t loss: 0.091764\n",
            "Accuracy of the network on the 10000 test images: 80 %\n",
            "epoch: 15\t batch: 8000\t loss: 0.093003\n",
            "Accuracy of the network on the 10000 test images: 81 %\n",
            "epoch: 15\t batch: 9000\t loss: 0.090230\n",
            "Accuracy of the network on the 10000 test images: 80 %\n",
            "epoch: 15\t batch: 10000\t loss: 0.091393\n",
            "Accuracy of the network on the 10000 test images: 80 %\n",
            "epoch: 16\t batch: 1000\t loss: 0.085073\n",
            "Accuracy of the network on the 10000 test images: 81 %\n",
            "epoch: 16\t batch: 2000\t loss: 0.082378\n",
            "Accuracy of the network on the 10000 test images: 81 %\n",
            "epoch: 16\t batch: 3000\t loss: 0.088956\n",
            "Accuracy of the network on the 10000 test images: 81 %\n",
            "epoch: 16\t batch: 4000\t loss: 0.082526\n",
            "Accuracy of the network on the 10000 test images: 81 %\n",
            "epoch: 16\t batch: 5000\t loss: 0.088112\n",
            "Accuracy of the network on the 10000 test images: 81 %\n",
            "epoch: 16\t batch: 6000\t loss: 0.083392\n",
            "Accuracy of the network on the 10000 test images: 81 %\n",
            "epoch: 16\t batch: 7000\t loss: 0.088166\n",
            "Accuracy of the network on the 10000 test images: 81 %\n",
            "epoch: 16\t batch: 8000\t loss: 0.083832\n",
            "Accuracy of the network on the 10000 test images: 81 %\n",
            "epoch: 16\t batch: 9000\t loss: 0.086507\n",
            "Accuracy of the network on the 10000 test images: 81 %\n",
            "epoch: 16\t batch: 10000\t loss: 0.083603\n",
            "Accuracy of the network on the 10000 test images: 81 %\n",
            "epoch: 17\t batch: 1000\t loss: 0.084356\n",
            "Accuracy of the network on the 10000 test images: 81 %\n",
            "epoch: 17\t batch: 2000\t loss: 0.083790\n",
            "Accuracy of the network on the 10000 test images: 81 %\n",
            "epoch: 17\t batch: 3000\t loss: 0.079211\n",
            "Accuracy of the network on the 10000 test images: 81 %\n",
            "epoch: 17\t batch: 4000\t loss: 0.086292\n",
            "Accuracy of the network on the 10000 test images: 81 %\n",
            "epoch: 17\t batch: 5000\t loss: 0.084181\n",
            "Accuracy of the network on the 10000 test images: 81 %\n",
            "epoch: 17\t batch: 6000\t loss: 0.081937\n",
            "Accuracy of the network on the 10000 test images: 82 %\n",
            "epoch: 17\t batch: 7000\t loss: 0.082819\n",
            "Accuracy of the network on the 10000 test images: 82 %\n",
            "epoch: 17\t batch: 8000\t loss: 0.079450\n",
            "Accuracy of the network on the 10000 test images: 81 %\n",
            "epoch: 17\t batch: 9000\t loss: 0.080017\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}